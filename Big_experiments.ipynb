{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fcapy[all]\n",
        "!pip install frozendict\n",
        "!pip install ipynb\n",
        "!pip install sparselinear\n",
        "!pip install bitsets\n",
        "!pip install bitarray\n",
        "import torch\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cuda118.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "id": "vUUAJcTCV-CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, jaccard_score, recall_score, accuracy_score, classification_report\n",
        "\n",
        "from fcapy.context import FormalContext\n",
        "from fcapy.lattice import ConceptLattice\n",
        "\n",
        "from fcapy.visualizer import LineVizNx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams['figure.facecolor'] = (1,1,1,1)\n",
        "\n",
        "import neural_lib as nl\n",
        "\n",
        "from fcapy.utils.utils import powerset\n",
        "\n",
        "from fcapy import LIB_INSTALLED\n",
        "if LIB_INSTALLED['numpy']:\n",
        "    import numpy as np\n",
        "\n",
        "from sparselinear import SparseLinear"
      ],
      "metadata": {
        "id": "6k5nw-sHWBRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "O0OwLX-0IUbs"
      },
      "outputs": [],
      "source": [
        "# SIMILARITY SMC\n",
        "\n",
        "def sim_s(b1,b2, G, M):\n",
        "  un_b1b2 = b1.union(b2) # union of b1 and b2\n",
        "  int_b1b2 = b1.intersection(b2) # intersection of b1 and b2\n",
        "  len_un_b1b2 = len(un_b1b2) # length of union of b1 and b2\n",
        "  len_int_b1b2 = len(int_b1b2) # length of intersection of b1 and b2\n",
        "  len_M = len(M) # length of M\n",
        "  len_difM_un = len(M.difference(un_b1b2)) # |M- B1 un B2|\n",
        "  return (len_int_b1b2 + len_difM_un)/len_M\n",
        "\n",
        "# SIMILARITY J\n",
        "\n",
        "def sim_J(b1,b2, G, M):\n",
        "  un_b1b2 = b1.union(b2) # union of b1 and b2\n",
        "  int_b1b2 = b1.intersection(b2) # intersection of b1 and b2\n",
        "  len_un_b1b2 = len(un_b1b2) # length of union of b1 and b2\n",
        "  len_int_b1b2 = len(int_b1b2) # length of intersection of b1 and b2\n",
        "  return len_int_b1b2/len_un_b1b2\n",
        "\n",
        "# COHERENCE ES\n",
        "\n",
        "def coh_es(A,B,G,M,K):\n",
        "  sum_x1x2 = 0\n",
        "  len_A = len(A)\n",
        "  delit = len_A*(len_A-1)/2\n",
        "  if delit == 0:\n",
        "    return 0\n",
        "  for x1 in A:\n",
        "    for x2 in A:\n",
        "      if x1!=x2:\n",
        "        sum_x1x2+=sim_s(set(K.intention([x1])),set(K.intention([x2])), G, M) # upper sum\n",
        "  return  0.5*sum_x1x2/delit\n",
        "\n",
        "# COHERENCE EJ\n",
        "\n",
        "def coh_eJ(A,B,G,M,K):\n",
        "  sum_x1x2 = 0\n",
        "  len_A = len(A)\n",
        "  delit = len_A*(len_A-1)/2\n",
        "  if delit == 0:\n",
        "    return 0\n",
        "  for x1 in A:\n",
        "    for x2 in A:\n",
        "      if x1!= x2:\n",
        "        sum_x1x2+=sim_J(set(K.intention([x1])),set(K.intention([x2])), G, M) # upper sum\n",
        "  return  0.5*sum_x1x2/delit\n",
        "\n",
        "# 2EES\n",
        "\n",
        "def alpha2_ees(i, conc, G, M, K, L):\n",
        "  sum_coh_c = 0\n",
        "  count = 0\n",
        "  A = set(conc.extent)\n",
        "  B = set(conc.intent)\n",
        "  if coh_es(A,B,G,M,K) == 0:\n",
        "    return 0\n",
        "  a = set()\n",
        "  b = set()\n",
        "  UN = len(L.parents(i))\n",
        "  if UN == 0:\n",
        "    return 0\n",
        "  for k in L.parents(i):\n",
        "    c = L[k]\n",
        "    a = set(c.extent)\n",
        "    b = set(c.intent)\n",
        "    if coh_es(a,b, G, M, K)>coh_es(A,B, G, M, K):\n",
        "      pass\n",
        "    else:\n",
        "      count+=1\n",
        "      sum_coh_c+=coh_es(a,b, G, M, K)/coh_es(A,B,G,M,K)\n",
        "  if count == 0:\n",
        "    return 0\n",
        "  return 1-sum_coh_c/count\n",
        "\n",
        "# 2EEJ\n",
        "\n",
        "def alpha2_eeJ (i, conc, G, M, K, L):\n",
        "  sum_coh_c = 0\n",
        "  count = 0\n",
        "  A = set(conc.extent)\n",
        "  B = set(conc.intent)\n",
        "  if coh_eJ(A,B,G,M,K) == 0:\n",
        "    return 0\n",
        "  a = set()\n",
        "  b = set()\n",
        "  UN = len(L.parents(i))\n",
        "  if UN == 0:\n",
        "    return 0\n",
        "  for k in L.parents(i):\n",
        "    c = L[k]\n",
        "    a = set(c.extent)\n",
        "    b = set(c.intent)\n",
        "    if coh_eJ(a,b, G, M, K)>coh_eJ(A,B, G, M, K):\n",
        "      pass\n",
        "    else:\n",
        "      count+=1\n",
        "      sum_coh_c+=coh_eJ(a,b, G, M, K)/coh_eJ(A, B, G, M, K)\n",
        "  if count == 0:\n",
        "    return 0\n",
        "  return 1-sum_coh_c/count\n",
        "\n",
        "# 3EES\n",
        "def alpha3_ees(i, conc, G, M, K, L):\n",
        "  sum_coh_c = 0\n",
        "  count = 0\n",
        "  A = set(conc.extent)\n",
        "  B = set(conc.intent)\n",
        "  a = set()\n",
        "  b = set()\n",
        "  LN = len(L.children(i))\n",
        "  if LN == 0:\n",
        "    return 0\n",
        "  for k in L.children(i):\n",
        "    c = L[k]\n",
        "    a = set(c.extent)\n",
        "    b = set(c.intent)\n",
        "    if coh_es(a,b, G, M, K)<coh_es(A,B, G, M, K):\n",
        "      pass\n",
        "    else:\n",
        "      if coh_es(a,b, G, M, K) == 0:\n",
        "        pass\n",
        "      else:\n",
        "        count+=1\n",
        "        sum_coh_c+=coh_es(A,B,G,M, K)/coh_es(a,b, G, M, K)\n",
        "  if count == 0:\n",
        "    return 0\n",
        "  return sum_coh_c/count\n",
        "\n",
        "# 3EEJ\n",
        "\n",
        "def alpha3_eeJ (i, conc, G, M, K, L):\n",
        "  sum_coh_c = 0\n",
        "  count = 0\n",
        "  A = set(conc.extent)\n",
        "  B = set(conc.intent)\n",
        "  a = set()\n",
        "  b = set()\n",
        "  LN = len(L.children(i))\n",
        "  if LN == 0:\n",
        "    return 0\n",
        "  for k in L.children(i):\n",
        "    c = L[k]\n",
        "    a = set(c.extent)\n",
        "    b = set(c.intent)\n",
        "    if coh_eJ(a,b, G, M, K)<coh_eJ(A,B, G, M, K):\n",
        "      pass\n",
        "    else:\n",
        "      if coh_eJ(a,b, G, M, K) == 0:\n",
        "        pass\n",
        "      else:\n",
        "        count+=1\n",
        "        sum_coh_c+=coh_eJ(A,B,G,M, K)/coh_eJ(a,b, G, M, K)\n",
        "  if count == 0:\n",
        "    return 0\n",
        "  return sum_coh_c/count\n",
        "\n",
        "# BASIC LEVEL\n",
        "\n",
        "# BL ees\n",
        "\n",
        "def BL_ees (i, conc, G, M,K, L):\n",
        "  return coh_es(set(conc.extent), set(conc.intent),G,M, K)*alpha2_ees(i, conc, G, M, K, L)*alpha3_ees(i, conc, G, M, K, L)\n",
        "\n",
        "# BL eeJ\n",
        "\n",
        "def BL_eeJ (i, conc, G, M,K, L):\n",
        "  return coh_eJ(set(conc.extent), set(conc.intent),G,M, K)*alpha2_eeJ(i, conc, G, M, K, L)*alpha3_eeJ(i, conc, G, M, K, L)\n",
        "\n",
        "# DELTA_STABILITY\n",
        "\n",
        "import math\n",
        "\n",
        "def log_stability_lbound(c_i, lattice: ConceptLattice, n_bin_attrs: int) -> float:\n",
        "    extent_i = set(lattice[c_i].extent_i)\n",
        "    children_i = lattice.children(c_i)\n",
        "    if children_i:\n",
        "        bound = min(len(extent_i - set(lattice[child_i].extent_i)) for child_i in children_i)\n",
        "    else:\n",
        "        bound = math.inf\n",
        "    bound -= math.log2(n_bin_attrs)\n",
        "    return bound\n",
        "\n",
        "def delta_stability(c_i, lattice: ConceptLattice, n_bin_attrs: int) -> float:\n",
        "    return log_stability_lbound(c_i, lattice, n_bin_attrs)+math.log2(n_bin_attrs)\n",
        "\n",
        "\n",
        "# TARGET ENTROPY (taken from FCApy)\n",
        "\n",
        "def target_entropy(c_i, lattice: ConceptLattice, context: FormalContext):\n",
        "    \"\"\"Compute the entropy of target labels of objects from concept extent\"\"\"\n",
        "    target_ext = context.target[list(lattice[c_i].extent_i)]\n",
        "    return np.var(target_ext)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtuZUQQBL0K4"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZPCz_CBEL206"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv('/content/heart_disease_bin_prep.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell contains code for iris dataset\n",
        "df_unp= pd.read_csv('/content/iris_dataset.csv')\n",
        "df = pd.DataFrame()\n",
        "df['sepalLength1'] = df_unp['sepalLength'] == 1\n",
        "df['sepalLength2'] = df_unp['sepalLength'] == 2\n",
        "df['sepalLength3'] = df_unp['sepalLength'] == 3\n",
        "df['sepalLength4'] = df_unp['sepalLength'] == 4\n",
        "df['sepalLength5'] = df_unp['sepalLength'] == 5\n",
        "df['sepalWidth6'] = df_unp['sepalWidth'] == 6\n",
        "df['sepalWidth7'] = df_unp['sepalWidth'] ==7\n",
        "df['sepalWidth8'] = df_unp['sepalWidth'] == 8\n",
        "df['sepalWidth9'] = df_unp['sepalWidth'] ==9\n",
        "df['sepalWidth10'] = df_unp['sepalWidth'] == 10\n",
        "df['petalLength11'] = df_unp['petalLength'] == 11\n",
        "df['petalLength12'] = df_unp['petalLength'] == 12\n",
        "df['petalLength13'] = df_unp['petalLength'] == 13\n",
        "df['petalWidth14'] = df_unp['petalLength'] == 14\n",
        "df['petalWidth15'] = df_unp['petalWidth'] == 15\n",
        "df['petalWidth16'] = df_unp['petalWidth'] == 16\n",
        "df['class'] = df_unp['class'] -17"
      ],
      "metadata": {
        "id": "10cDQLYl_HoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xiosQJ8kL5hD"
      },
      "outputs": [],
      "source": [
        "df['sample_id'] = np.arange(0, df.shape[0], 1).astype(str)\n",
        "df['id'] = df['sample_id'].apply(lambda x: 'h' + x)\n",
        "df.drop(columns=['sample_id'], inplace=True)\n",
        "df = df.set_index('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sMqAdRh0L8Yn"
      },
      "outputs": [],
      "source": [
        "y_feat = 'target' # y_feat = 'class' for iris dataset\n",
        "df_train, df_test = train_test_split(df, train_size=0.7, random_state=0)\n",
        "\n",
        "x_train, y_train = df_train.drop(y_feat, axis=1), df_train[y_feat]\n",
        "x_test, y_test = df_test.drop(y_feat, axis=1), df_test[y_feat]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fIgjixB8L-3x"
      },
      "outputs": [],
      "source": [
        "# Creating Formal Context\n",
        "%%time\n",
        "K = FormalContext(data = x_train.values, target = y_train.values, attribute_names=x_train.columns)\n",
        "K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "E6bk4wWHMBSp"
      },
      "outputs": [],
      "source": [
        "# Computing Formal Concepts\n",
        "%%time\n",
        "\n",
        "L= ConceptLattice.from_context(K, algo='Sofia', is_monotone=True)\n",
        "len(L)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_JvvWl1MQau"
      },
      "source": [
        "# MEASURES"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = set(df.index) # set of objects\n",
        "M =  set(df.columns) # set of attributes"
      ],
      "metadata": {
        "id": "T9xARcoo8o08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating indexes for concepts\n",
        "for i in range(len(L)):\n",
        "  L[i].measures[ 'BL_ees'] =  BL_ees(i, L[i], G, M, K, L)\n",
        "  L[i].measures[ 'BL_eeJ'] =  BL_eeJ(i, L[i], G, M, K, L)\n",
        "  L[i].measures[ 'target_entropy'] =  target_entropy(i, L, K)\n",
        "  L[i].measures[ 'delta_stability'] = delta_stability(i, L, len(M))"
      ],
      "metadata": {
        "id": "Ke1GfYmtF-DX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell contains code for computing lift interest indexes\n",
        "b_i = ''\n",
        "B = []\n",
        "lifts = []\n",
        "lift_i = 0\n",
        "Pr_B = 1\n",
        "Mult_Bi = 1\n",
        "pair = []\n",
        "for i in range(len(L)):\n",
        "  for attr in L[i].intent:\n",
        "     B.append(attr)\n",
        "  if len(K.extension(B)) == 0:\n",
        "    L[i].measures[ 'lift'] = 0\n",
        "  else:\n",
        "    Pr_B = len(K.extension(B))/len(G)\n",
        "    for b_i in B:\n",
        "      Mult_Bi*=len(K.extension([b_i]))/len(G)\n",
        "    lift_i = Mult_Bi/Pr_B\n",
        "    pair.append(i)\n",
        "    pair.append(lift_i)\n",
        "    lifts.append(pair)\n",
        "    L[i].measures[ 'lift'] = lift_i\n",
        "    b_i =''\n",
        "    B = []\n",
        "    lift_i = 0\n",
        "    Pr_B = 0\n",
        "    Mult_Bi = 1\n",
        "    pair = []\n",
        "print(lifts)"
      ],
      "metadata": {
        "id": "7YcHT_yMeooB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding best concept using indexes sort"
      ],
      "metadata": {
        "id": "G1kgFmroYq16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7C5BW6zMiUP"
      },
      "outputs": [],
      "source": [
        "n_concepts_s =7\n",
        "best_concepts_s = list(L.measures['BL_ees'].argsort()[::-1][:n_concepts_s])\n",
        "assert len({g_i for c in L[best_concepts_s] for g_i in c.extent_i})==K.n_objects, \"Selected concepts do not cover all train objects\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_concepts_J =7\n",
        "best_concepts_J  = []\n",
        "best_concepts_J = list(L.measures['BL_eeJ'].argsort()[::-1][:n_concepts_J])\n",
        "assert len({g_i for c in L[best_concepts_J] for g_i in c.extent_i})==K.n_objects, \"Selected concepts do not cover all train objects\""
      ],
      "metadata": {
        "id": "xYvgTmiEkwxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_concepts_t =20\n",
        "best_concepts_t  = []\n",
        "best_concepts_t = list(L.measures['target_entropy'].argsort()[::-1][:n_concepts_t])\n",
        "assert len({g_i for c in L[best_concepts_t] for g_i in c.extent_i})==K.n_objects, \"Selected concepts do not cover all train objects\""
      ],
      "metadata": {
        "id": "eVqT4LTlkw6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_concepts_d =7\n",
        "best_concepts_d = []\n",
        "best_concepts_d = list(L.measures['delta_stability'].argsort()[::-1][:n_concepts_d])\n",
        "assert len({g_i for c in L[best_concepts_d] for g_i in c.extent_i})==K.n_objects, \"Selected concepts do not cover all train objects\""
      ],
      "metadata": {
        "id": "I2Pc-S4kkxCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_concepts_l =7\n",
        "best_concepts_l = []\n",
        "best_concepts_l = list(L.measures['lift'].argsort()[::-1][:n_concepts_l])\n",
        "assert len({g_i for c in L[best_concepts_l] for g_i in c.extent_i})==K.n_objects, \"Selected concepts do not cover all train objects\""
      ],
      "metadata": {
        "id": "dzUPRTIPkxLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cn = 0"
      ],
      "metadata": {
        "id": "w-W9cQOveFXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating nn from concept lattice using best concepts\n",
        "cn = nl.ConceptNetwork.from_lattice(L, best_concepts_J, sorted(set(y_train)))"
      ],
      "metadata": {
        "id": "EWINH7jfMI-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cn.fit(x_train, y_train,  n_epochs =2000) # nn fitting"
      ],
      "metadata": {
        "id": "A0qwctxNmBO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn prediction on test data\n",
        "y_pred = cn.predict(x_test).numpy()\n",
        "print('Class prediction', y_pred[:10])\n",
        "y_proba = cn.predict_proba(x_test).detach().numpy()\n",
        "print('Class prediction with probabilities', y_proba[:10])\n",
        "print('True class', y_test.values[:10])"
      ],
      "metadata": {
        "id": "D1K-EOYKnvtK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j8Ut-gnaM67G"
      },
      "outputs": [],
      "source": [
        "# metrics evaluation on test data\n",
        "print('Recall score:', recall_score(y_test.values.astype('int'), y_pred))\n",
        "print('F1     score:', f1_score(y_test.values.astype('int'), y_pred))\n",
        "print('Accuracy score:', accuracy_score(y_test.values.astype('int'), y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NhL-r86bM_-7"
      },
      "outputs": [],
      "source": [
        "# prediction on train data (double check)\n",
        "y_pred = cn.predict(x_train).numpy()\n",
        "print('Class prediction', y_pred[:10])\n",
        "y_proba = cn.predict_proba(x_train).detach().numpy()\n",
        "print('Class prediction with probabilities', y_proba[:10])\n",
        "print('True class', y_train.values[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LcCIMsxDNCSP"
      },
      "outputs": [],
      "source": [
        "# metrics evaluation on train data (double check)\n",
        "print('Recall score:', recall_score(y_train.values.astype('int'), y_pred, average='micro'))\n",
        "print('F1     score:', f1_score(y_train.values.astype('int'), y_pred, average='micro'))\n",
        "print('Accuracy score:', accuracy_score(y_train.values.astype('int'), y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}